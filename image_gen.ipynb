{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:34.467534Z",
     "start_time": "2025-10-01T21:12:34.464123Z"
    }
   },
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.amp import autocast, GradScaler\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:34.504607Z",
     "start_time": "2025-10-01T21:12:34.471633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_dim = 128\n",
    "device = 'cuda'\n",
    "num_time_channels = 29\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "show_every = 1000"
   ],
   "id": "93335bb7a7bb9ca0",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:34.847748Z",
     "start_time": "2025-10-01T21:12:34.518426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dset = torchvision.datasets.Flowers102(root='data/flowers-102',\n",
    "                                       download=True,\n",
    "                                       transform=transforms.Compose(\n",
    "                                           (transforms.Resize((image_dim, image_dim)),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
    "                                       )\n",
    "                                       )\n",
    "dldr = DataLoader(dset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "next(iter(dldr))[0].shape"
   ],
   "id": "dfaa8561e7b36c47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 128, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:34.862236Z",
     "start_time": "2025-10-01T21:12:34.855062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fourier_time_features(batch_n, shape, time_samples):\n",
    "\n",
    "    # Vectorized computation\n",
    "    i_vec = torch.linspace(0, num_time_channels - 1, num_time_channels)\n",
    "    factor = torch.exp(math.log(10_000) * i_vec / num_time_channels).to(device)\n",
    "    factor = factor.view(1, -1)\n",
    "    \n",
    "    # Compute all angles at once: [batch, num_time_channels]\n",
    "    angles = time_samples.view(-1, 1) / factor\n",
    "    \n",
    "    # Create cos and sin features: [batch, num_time_channels]\n",
    "    cos_features = torch.cos(angles)\n",
    "    sin_features = torch.sin(angles)\n",
    "    \n",
    "    # Alternate cos and sin: even indices = cos, odd indices = sin\n",
    "    time_features = torch.zeros((batch_n, num_time_channels, *shape), device=device)\n",
    "    time_features[:, ::2, ...] = cos_features[:, ::2].view(batch_n, -1, 1, 1)\n",
    "    time_features[:, 1::2, ...] = sin_features[:, 1::2].view(batch_n, -1, 1, 1)\n",
    "    \n",
    "    return time_features\n",
    "\n",
    "fourier_time_features(batch_size, (image_dim, image_dim), torch.ones(batch_size, device=device)).shape"
   ],
   "id": "f470bc8e7b781526",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 29, 128, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:34.908685Z",
     "start_time": "2025-10-01T21:12:34.905402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def time_coefficients(time_values):\n",
    "    time_values = torch.clamp(time_values, 0, 1)\n",
    "    a_t = 1-time_values\n",
    "    b_t = time_values\n",
    "    return a_t.view((-1, 1, 1, 1)), b_t.view((-1, 1, 1, 1))"
   ],
   "id": "3dd6698e01946a49",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:34.958071Z",
     "start_time": "2025-10-01T21:12:34.952520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualLinear(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualLinear, self).__init__()\n",
    "        self.linear = nn.Sequential(nn.Linear(dim, 1024),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(1024, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        out = x.view((shape[0], -1))\n",
    "        out = self.linear(out)\n",
    "        out = out.view(shape)\n",
    "        return x+out\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, depth, channels, image_dims):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv_down = nn.Sequential(nn.Conv2d(in_channels=channels, out_channels=channels*2, kernel_size=3, stride=2, padding=1),\n",
    "                                       nn.BatchNorm2d(channels*2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.AdaptiveMaxPool2d((image_dims // 2, image_dims // 2)), )\n",
    "\n",
    "        self.conv_up = nn.Sequential(nn.ConvTranspose2d(in_channels=channels*4, out_channels=channels, kernel_size=3, stride=2, padding=1),\n",
    "                                     nn.BatchNorm2d(channels),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.AdaptiveMaxPool2d((image_dims, image_dims)), )\n",
    "\n",
    "        if depth>1:\n",
    "            self.sub_net = UNet(depth - 1, channels*2, image_dims // 2)\n",
    "        else:\n",
    "            self.sub_net = ResidualLinear(channels*2 * (image_dims // 2)**2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_down(x)\n",
    "        out = self.sub_net(x)\n",
    "        x = torch.cat((x, out), dim=1)\n",
    "        x = self.conv_up(x)\n",
    "        return x"
   ],
   "id": "e7c55eb440a8f701",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:35.550379Z",
     "start_time": "2025-10-01T21:12:35.003055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flow_net = nn.Sequential(nn.BatchNorm2d(3+num_time_channels),UNet(6, 3+num_time_channels, image_dim), nn.Conv2d(3+num_time_channels, 3, 1)).to(device)\n",
    "flow_net.compile()\n",
    "flow_net"
   ],
   "id": "1df7d66941c25715",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): UNet(\n",
       "    (conv_down): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): AdaptiveMaxPool2d(output_size=(64, 64))\n",
       "    )\n",
       "    (conv_up): Sequential(\n",
       "      (0): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): AdaptiveMaxPool2d(output_size=(128, 128))\n",
       "    )\n",
       "    (sub_net): UNet(\n",
       "      (conv_down): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaptiveMaxPool2d(output_size=(32, 32))\n",
       "      )\n",
       "      (conv_up): Sequential(\n",
       "        (0): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaptiveMaxPool2d(output_size=(64, 64))\n",
       "      )\n",
       "      (sub_net): UNet(\n",
       "        (conv_down): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): AdaptiveMaxPool2d(output_size=(16, 16))\n",
       "        )\n",
       "        (conv_up): Sequential(\n",
       "          (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): AdaptiveMaxPool2d(output_size=(32, 32))\n",
       "        )\n",
       "        (sub_net): UNet(\n",
       "          (conv_down): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): AdaptiveMaxPool2d(output_size=(8, 8))\n",
       "          )\n",
       "          (conv_up): Sequential(\n",
       "            (0): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): AdaptiveMaxPool2d(output_size=(16, 16))\n",
       "          )\n",
       "          (sub_net): UNet(\n",
       "            (conv_down): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "              (3): AdaptiveMaxPool2d(output_size=(4, 4))\n",
       "            )\n",
       "            (conv_up): Sequential(\n",
       "              (0): ConvTranspose2d(2048, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "              (3): AdaptiveMaxPool2d(output_size=(8, 8))\n",
       "            )\n",
       "            (sub_net): UNet(\n",
       "              (conv_down): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "                (3): AdaptiveMaxPool2d(output_size=(2, 2))\n",
       "              )\n",
       "              (conv_up): Sequential(\n",
       "                (0): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "                (3): AdaptiveMaxPool2d(output_size=(4, 4))\n",
       "              )\n",
       "              (sub_net): ResidualLinear(\n",
       "                (linear): Sequential(\n",
       "                  (0): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "                  (1): LeakyReLU(negative_slope=0.01)\n",
       "                  (2): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:35.559993Z",
     "start_time": "2025-10-01T21:12:35.556317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.SmoothL1Loss()\n",
    "scaler = GradScaler()\n",
    "optim = torch.optim.Adam(flow_net.parameters(), fused=True, lr=1e-3)"
   ],
   "id": "561af3534011661c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T21:12:35.606354Z",
     "start_time": "2025-10-01T21:12:35.602663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "def sample_pic(step):\n",
    "    n_steps = 10\n",
    "    x_t = torch.randn((1, 3, image_dim, image_dim)).to(device)\n",
    "    flow_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for j in range(n_steps):\n",
    "            time_values = j / n_steps * torch.ones(1).to(device)\n",
    "            fourier_features = fourier_time_features(1, (image_dim, image_dim), time_values)\n",
    "            x_t_in = torch.cat([x_t, fourier_features], dim=1)\n",
    "            velocity_values = flow_net(x_t_in)\n",
    "            x_t += velocity_values/n_steps\n",
    "\n",
    "    mlflow.log_image((x_t[0].permute(1, 2, 0).cpu().clamp(-1, 1).numpy() + 1) / 2, key=f\"generated-image-{step:05d}\")\n",
    "    flow_net.train()"
   ],
   "id": "ec4f0eab2e012515",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-01T21:12:35.662549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with mlflow.start_run():\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        try:\n",
    "            for i, batch in enumerate(dldr):\n",
    "                x_1, _ = batch\n",
    "                x_0 = torch.randn((x_1.shape[0], 3, image_dim, image_dim), device=device)\n",
    "                x_1 = x_1.to(device)\n",
    "\n",
    "                times = torch.rand(x_0.shape[0]).to(device)\n",
    "                a, b = time_coefficients(times)\n",
    "\n",
    "                x_t = a * x_0 + b * x_1\n",
    "                fourier = fourier_time_features(x_t.shape[0], (image_dim, image_dim), times)\n",
    "\n",
    "                x_in = torch.cat((x_t, fourier), dim=1)\n",
    "\n",
    "                with autocast(device_type=device):\n",
    "                    velocity = flow_net(x_in)\n",
    "                    loss = loss_fn(velocity, x_1 - x_0)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "\n",
    "                mlflow.log_metrics({'scalars/loss': loss.item(),\n",
    "                                    'scalars/velocity_estimate': (velocity**2).mean()**0.5,\n",
    "                                    'scalars/velocity_real': ((x_1-x_0)**2).mean()**0.5}, step=len(dldr) * epoch + i)\n",
    "\n",
    "                if i%(show_every//batch_size) == (show_every//batch_size) - 1:\n",
    "                    sample_pic(len(dldr) * epoch + i)\n",
    "        except KeyboardInterrupt as e:\n",
    "            torch.save(flow_net.state_dict(), 'flow_net.pth')\n",
    "            raise e"
   ],
   "id": "76dba66a5228d0b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(flow_net.state_dict(), 'flow_net.pth')",
   "id": "1e9b7d38cbfa21b1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
