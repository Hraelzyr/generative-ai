{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.024138Z",
     "start_time": "2025-10-06T20:37:37.013589Z"
    }
   },
   "source": [
    "import math\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.amp import autocast, GradScaler\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "mlflow.set_experiment(\"image-gen\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/527894522082058475', creation_time=1759781409349, experiment_id='527894522082058475', last_update_time=1759781409349, lifecycle_stage='active', name='image-gen', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.065676Z",
     "start_time": "2025-10-06T20:37:37.062239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_dim = 128\n",
    "device = 'cuda'\n",
    "num_time_channels = 13\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "show_every = 1000\n",
    "do_load = True\n",
    "params = {\n",
    "    'image_dim': image_dim,\n",
    "    'num_time_channels': num_time_channels,\n",
    "    'batch_size': batch_size,\n",
    "    'num_epochs': num_epochs,\n",
    "    'device': device,\n",
    "    'do_load': do_load,\n",
    "}"
   ],
   "id": "93335bb7a7bb9ca0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.395165Z",
     "start_time": "2025-10-06T20:37:37.108494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dset = torchvision.datasets.Flowers102(root='data/flowers-102',\n",
    "                                       download=True,\n",
    "                                       transform=transforms.Compose(\n",
    "                                           (transforms.Resize((image_dim, image_dim)),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
    "                                       )\n",
    "                                       )\n",
    "dldr = DataLoader(dset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "next(iter(dldr))[0].shape"
   ],
   "id": "dfaa8561e7b36c47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 128, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.420543Z",
     "start_time": "2025-10-06T20:37:37.404229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fourier_time_features(batch_n, shape, time_samples):\n",
    "\n",
    "    # Vectorized computation\n",
    "    i_vec = torch.linspace(0, num_time_channels - 1, num_time_channels)\n",
    "    factor = torch.exp(math.log(10_000) * i_vec / num_time_channels).to(device)\n",
    "    factor = factor.view(1, -1)\n",
    "    \n",
    "    # Compute all angles at once: [batch, num_time_channels]\n",
    "    angles = time_samples.view(-1, 1) / factor\n",
    "    \n",
    "    # Create cos and sin features: [batch, num_time_channels]\n",
    "    cos_features = torch.cos(angles)\n",
    "    sin_features = torch.sin(angles)\n",
    "    \n",
    "    # Alternate cos and sin: even indices = cos, odd indices = sin\n",
    "    time_features = torch.zeros((batch_n, num_time_channels, *shape), device=device)\n",
    "    time_features[:, ::2, ...] = cos_features[:, ::2].view(batch_n, -1, 1, 1)\n",
    "    time_features[:, 1::2, ...] = sin_features[:, 1::2].view(batch_n, -1, 1, 1)\n",
    "    \n",
    "    return time_features\n",
    "\n",
    "fourier_time_features(batch_size, (image_dim, image_dim), torch.ones(batch_size, device=device)).shape"
   ],
   "id": "f470bc8e7b781526",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 13, 128, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.456951Z",
     "start_time": "2025-10-06T20:37:37.453397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def time_coefficients(time_values):\n",
    "    time_values = torch.clamp(time_values, 0, 1)\n",
    "    a_t = 1-time_values\n",
    "    b_t = time_values\n",
    "    return a_t.view((-1, 1, 1, 1)), b_t.view((-1, 1, 1, 1))"
   ],
   "id": "3dd6698e01946a49",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.507375Z",
     "start_time": "2025-10-06T20:37:37.500239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualLinear(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualLinear, self).__init__()\n",
    "        self.linear = nn.Sequential(nn.Linear(dim, 1024),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(1024, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        out = x.view((shape[0], -1))\n",
    "        out = self.linear(out)\n",
    "        out = out.view(shape)\n",
    "        return x+out\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, depth, channels, image_dims):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv_down = nn.Sequential(nn.Conv2d(in_channels=channels, out_channels=channels*2, kernel_size=3, stride=2, padding=1),\n",
    "                                       nn.BatchNorm2d(channels*2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.AdaptiveMaxPool2d((image_dims // 2, image_dims // 2)), )\n",
    "\n",
    "        self.conv_up = nn.Sequential(nn.ConvTranspose2d(in_channels=channels*4, out_channels=channels, kernel_size=3, stride=2, padding=1),\n",
    "                                     nn.BatchNorm2d(channels),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.AdaptiveMaxPool2d((image_dims, image_dims)), )\n",
    "\n",
    "        if depth>1:\n",
    "            self.sub_net = UNet(depth - 1, channels*2, image_dims // 2)\n",
    "        else:\n",
    "            self.sub_net = ResidualLinear(channels*2 * (image_dims // 2)**2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_down(x)\n",
    "        out = self.sub_net(x)\n",
    "        x = torch.cat((x, out), dim=1)\n",
    "        x = self.conv_up(x)\n",
    "        return x"
   ],
   "id": "e7c55eb440a8f701",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.719271Z",
     "start_time": "2025-10-06T20:37:37.550927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flow_net = nn.Sequential(nn.BatchNorm2d(3+num_time_channels),UNet(6, 3+num_time_channels, image_dim), nn.Conv2d(3+num_time_channels, 3, 1)).to(device)\n",
    "#flow_net.compile()\n",
    "if os.path.exists('./flow_net.pth') and do_load:\n",
    "    flow_net.load_state_dict(torch.load('./flow_net.pth'))\n",
    "flow_net"
   ],
   "id": "1df7d66941c25715",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): UNet(\n",
       "    (conv_down): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): AdaptiveMaxPool2d(output_size=(64, 64))\n",
       "    )\n",
       "    (conv_up): Sequential(\n",
       "      (0): ConvTranspose2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): AdaptiveMaxPool2d(output_size=(128, 128))\n",
       "    )\n",
       "    (sub_net): UNet(\n",
       "      (conv_down): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaptiveMaxPool2d(output_size=(32, 32))\n",
       "      )\n",
       "      (conv_up): Sequential(\n",
       "        (0): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaptiveMaxPool2d(output_size=(64, 64))\n",
       "      )\n",
       "      (sub_net): UNet(\n",
       "        (conv_down): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): AdaptiveMaxPool2d(output_size=(16, 16))\n",
       "        )\n",
       "        (conv_up): Sequential(\n",
       "          (0): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): AdaptiveMaxPool2d(output_size=(32, 32))\n",
       "        )\n",
       "        (sub_net): UNet(\n",
       "          (conv_down): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): AdaptiveMaxPool2d(output_size=(8, 8))\n",
       "          )\n",
       "          (conv_up): Sequential(\n",
       "            (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): AdaptiveMaxPool2d(output_size=(16, 16))\n",
       "          )\n",
       "          (sub_net): UNet(\n",
       "            (conv_down): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "              (3): AdaptiveMaxPool2d(output_size=(4, 4))\n",
       "            )\n",
       "            (conv_up): Sequential(\n",
       "              (0): ConvTranspose2d(1024, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU()\n",
       "              (3): AdaptiveMaxPool2d(output_size=(8, 8))\n",
       "            )\n",
       "            (sub_net): UNet(\n",
       "              (conv_down): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "                (3): AdaptiveMaxPool2d(output_size=(2, 2))\n",
       "              )\n",
       "              (conv_up): Sequential(\n",
       "                (0): ConvTranspose2d(2048, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "                (3): AdaptiveMaxPool2d(output_size=(4, 4))\n",
       "              )\n",
       "              (sub_net): ResidualLinear(\n",
       "                (linear): Sequential(\n",
       "                  (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (1): LeakyReLU(negative_slope=0.01)\n",
       "                  (2): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.731214Z",
     "start_time": "2025-10-06T20:37:37.727880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.SmoothL1Loss()\n",
    "scaler = GradScaler()\n",
    "optim = torch.optim.Adam(flow_net.parameters(), fused=True, lr=1e-3)"
   ],
   "id": "561af3534011661c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:37:37.779207Z",
     "start_time": "2025-10-06T20:37:37.774352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_pic(step):\n",
    "    n_steps = 10\n",
    "    x_t = torch.randn((1, 3, image_dim, image_dim)).to(device)\n",
    "    flow_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for j in range(n_steps):\n",
    "            time_values = j / n_steps * torch.ones(1).to(device)\n",
    "            fourier_features = fourier_time_features(1, (image_dim, image_dim), time_values)\n",
    "            x_t_in = torch.cat([x_t, fourier_features], dim=1)\n",
    "            velocity_values = flow_net(x_t_in)\n",
    "            time_value = (j+1)/n_steps\n",
    "            var = (1-time_value)/time_value\n",
    "            x_t += (2*velocity_values - x_t/time_value)/n_steps + \\\n",
    "                    math.sqrt(2*var/n_steps)*torch.randn_like(velocity_values)\n",
    "\n",
    "    mlflow.log_image((x_t[0].permute(1, 2, 0).cpu().clamp(-1, 1).numpy() + 1) / 2, key=f\"generated-image-{step:05d}\")\n",
    "    flow_net.train()"
   ],
   "id": "ec4f0eab2e012515",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:41:00.172176Z",
     "start_time": "2025-10-06T20:37:37.822985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        try:\n",
    "            for i, batch in enumerate(dldr):\n",
    "                x_1, _ = batch\n",
    "                x_0 = torch.randn_like(x_1, device=device)\n",
    "                x_1 = x_1.to(device)\n",
    "\n",
    "                times = torch.rand(x_0.shape[0]).to(device)\n",
    "                a, b = time_coefficients(times)\n",
    "\n",
    "                x_t = a * x_0 + b * x_1\n",
    "                fourier = fourier_time_features(x_t.shape[0], (image_dim, image_dim), times)\n",
    "\n",
    "                x_in = torch.cat((x_t, fourier), dim=1)\n",
    "\n",
    "                with autocast(device_type=device):\n",
    "                    velocity = flow_net(x_in)\n",
    "                    loss = loss_fn(velocity, x_1 - x_0)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "\n",
    "                mlflow.log_metrics({'scalars/loss': loss.item(),\n",
    "                                    'scalars/velocity_estimate': (velocity**2).mean()**0.5,\n",
    "                                    'scalars/velocity_real': ((x_1-x_0)**2).mean()**0.5}, step=len(dldr) * epoch + i)\n",
    "\n",
    "                if i%(show_every//batch_size) == (show_every//batch_size) - 1:\n",
    "                    sample_pic(len(dldr) * epoch + i)\n",
    "        except KeyboardInterrupt as e:\n",
    "            torch.save(flow_net.state_dict(), 'flow_net.pth')\n",
    "            raise e"
   ],
   "id": "76dba66a5228d0b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n",
      "üèÉ View run skillful-frog-547 at: http://localhost:5000/#/experiments/527894522082058475/runs/6ab4808c65b14347ad7261b8fda9138b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/527894522082058475\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:41:00.497581Z",
     "start_time": "2025-10-06T20:41:00.341054Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(flow_net.state_dict(), 'flow_net.pth')",
   "id": "1e9b7d38cbfa21b1",
   "outputs": [],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
